{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Let’s try using the Trainer feature\n",
    "\n",
    "By using [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer), you don’t need to write the tedious training loop explicitly any more. Furthermore, Chainer provides many useful extensions that can be used with [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) to visualize your results, evaluate your model, store and manage log files more easily.\n",
    "\n",
    "This example will show how to use the [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) to train a fully-connected feed-forward neural network on the MNIST dataset.\n",
    "\n",
    "**Note**\n",
    "\n",
    "If you would like to know how to write a training loop without using this functionality, please check [How to write a training loop in Chainer](training_loop_in_chainer.ipynb) instead of this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First, let's import the necessary packages for using Chainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Prepare the dataset\n",
    "\n",
    "Load the MNIST dataset, which contains a training set of images and class labels as well as a corresponding test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from chainer.datasets import mnist\n",
    "\n",
    "train, test = mnist.get_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note**\n",
    "You can use a **Python list as a dataset**. Because all types of objects whose element can be accessed via `[]` accessor and lengh can be obtained with `len()` function, can be used as a dataset given to the [Iterator](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.Iterator.html#chainer.dataset.Iterator). For example,\n",
    "\n",
    "```\n",
    "train = [(x1, t1), (x2, t2), ...]\n",
    "```\n",
    "\n",
    "a list of tuples like this can also be used equally to a [DatasetMixin](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.DatasetMixin.html#chainer.dataset.DatasetMixin) object.\n",
    "\n",
    "But many useful abstracted [datasets](https://docs.chainer.org/en/latest/reference/datasets.html#module-chainer.datasets) enable to avoid storing all data on the memory at a time, so it’s better to use them for large datasets. For example, [ImageDataset](https://docs.chainer.org/en/latest/reference/generated/chainer.datasets.ImageDataset.html#chainer.datasets.ImageDataset) takes paths to image files as its argument, and just keep the list in the dataset object. It means the actual image data will be loaded from disks using given paths when [\\_\\_getitem\\_\\_()](https://docs.chainer.org/en/latest/reference/generated/chainer.datasets.ImageDataset.html#chainer.datasets.ImageDataset.__getitem__) is called. Until then, no images are loaded to the memory, so it can save the memory consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2. Prepare the dataset iterations\n",
    "\n",
    "[Iterator](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.Iterator.html#chainer.dataset.Iterator) creates a mini-batch from the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 3. Prepare the model\n",
    "\n",
    "Here, we are going to use the same model as defined in [How to write a training loop in Chainer](1_training_loop_in_chainer.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "\n",
    "    def __init__(self, n_mid_units=100, n_out=10):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_mid_units)\n",
    "            self.l2 = L.Linear(None, n_mid_units)\n",
    "            self.l3 = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "model = MLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Prepare the Updater\n",
    "\n",
    "[Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) is a class that holds all of the necessary components needed for training. The main components are shown below.\n",
    "\n",
    "![](trainer.png)\n",
    "\n",
    "Basically, all you need to pass to [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) is an [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater). However, [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater) contains an [Iterator](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.Iterator.html#chainer.dataset.Iterator) and [Optimizer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Optimizer.html#chainer.Optimizer). Since [Iterator](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.Iterator.html#chainer.dataset.Iterator) can access the dataset and [Optimizer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Optimizer.html#chainer.Optimizer) has references to the model, [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater) can access to the model to update its parameters.\n",
    "\n",
    "So, [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater) can perform the training procedure as shown below:\n",
    "\n",
    "Retrieve the data from dataset and construct a mini-batch ([Iterator](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.Iterator.html#chainer.dataset.Iterator))\n",
    "Pass the mini-batch to the model and calculate the loss\n",
    "Update the parameters of the model ([Optimizer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Optimizer.html#chainer.Optimizer))\n",
    "\n",
    "Now let’s create the [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater) object !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "\n",
    "# Wrapp your model by Classifier and include the process of loss calculation within your model.\n",
    "# Since we do not specify a loss funciton here, the default 'softmax_cross_entropy' is used.\n",
    "model = L.Classifier(model)\n",
    "\n",
    "gpu_id = 0  # Set to -1 if you use CPU\n",
    "if gpu_id >= 0:\n",
    "    model.to_gpu(gpu_id)  # If you use CPU, comment out this line\n",
    "\n",
    "# selection of your optimizing method\n",
    "optimizer = optimizers.MomentumSGD()\n",
    "\n",
    "# Give the optimizer a reference to the model\n",
    "optimizer.setup(model)\n",
    "\n",
    "# Get an updater that uses the Iterator and Optimizer\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Note**\n",
    "\n",
    "Here, the model defined above is passed to [Classifier](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier) and changed to a new [Chain](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Chain.html#chainer.Chain). [Classifier](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier), which in fact inherits from the [Chain](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Chain.html#chainer.Chain) class, keeps the given [Chain](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Chain.html#chainer.Chain) model in its `predictor` attribute. Once you give the input data and the corresponding class labels to the model by the `()` accessor,\n",
    "\n",
    "1. [\\_\\_call\\_\\_()](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier.__call__) of the model is invoked. The data is then given to `predictor` to obtain the output `y`.\n",
    "2. Next, together with the given labels, the output `y` is passed to the loss function which is determined by `lossfun` argument in the constructor of [Classifier](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier).\n",
    "The loss is returned as a [Variable](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Variable.html#chainer.Variable).\n",
    "\n",
    "In [Classifiler](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier), the `lossfun` is set to [softmax_cross_entropy()](https://docs.chainer.org/en/latest/reference/generated/chainer.functions.softmax_cross_entropy.html#chainer.functions.softmax_cross_entropy) as default.\n",
    "\n",
    "[StandardUpdater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.StandardUpdater.html#chainer.training.StandardUpdater) is the simplest class among several updaters. There are also the [ParallelUpdater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.ParallelUpdater.html#chainer.training.ParallelUpdater) and the [MultiprocessParallelUpdater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.updaters.MultiprocessParallelUpdater.html#chainer.training.updaters.MultiprocessParallelUpdater) to utilize multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 5. Setup Trainer\n",
    "\n",
    "Lastly, we will setup [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer). The only requirement for creating a [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) is to pass the [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater) object that we previously created above. You can also pass a stop_trigger to the second trainer argument as a tuple like `(length, unit)` to tell the trainer when to stop the training. The `length` is given as an integer and the `unit` is given as a string which should be either `'epoch'` or `'iteration'`. Without setting `stop_trigger`, the training will never be stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Setup a Trainer\n",
    "trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='mnist_result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `out` argument specifies an output directory used to save the log files, the image files of plots to show the time progress of loss, accuracy, etc. when you use [PlotReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.PlotReport.html#chainer.training.extensions.PlotReport) extension. Next, we will explain how to display or save those information by using trainer [Extension](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Extension.html#chainer.training.Extension)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 6. Add Extensions to the Trainer object\n",
    "\n",
    "The [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) extensions provide the following capabilites:\n",
    "\n",
    "- Save log files automatically ([LogReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.LogReport.html#chainer.training.extensions.LogReport))\n",
    "- Display the training information to the terminal periodically ([PrintReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.PrintReport.html#chainer.training.extensions.PrintReport))\n",
    "- Visualize the loss progress by plottig a graph periodically and save it as an image file ([PlotReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.PlotReport.html#chainer.training.extensions.PlotReport))\n",
    "- Automatically serialize the state periodically ([snapshot()](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.snapshot.html#chainer.training.extensions.snapshot) / [snapshot_object()](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.snapshot_object.html#chainer.training.extensions.snapshot_object))\n",
    "- Display a progress bar to the terminal to show the progress of training ([ProgressBar](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.ProgressBar.html#chainer.training.extensions.ProgressBar))\n",
    "- Save the model architechture as a Graphviz’s dot file ([dump_graph](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.dump_graph.html#chainer.training.extensions.dump_graph))\n",
    "\n",
    "To use these wide variety of tools for your tarining task, pass [Extension](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Extension.html#chainer.training.Extension) objects to the [extend()](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer.extend) method of your [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.snapshot_object(model.predictor, filename='model_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.extend(extensions.dump_graph('main/loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## [LogReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.LogReport.html#chainer.training.extensions.LogReport)\n",
    "\n",
    "Collect `loss` and `accuracy` automatically every `'epoch'` or `'iteration'` and store the information under the `log` file in the directory specified by the `out` argument when you create a [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) object.\n",
    "\n",
    "## [snapshot()](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.snapshot.html#chainer.training.extensions.snapshot)\n",
    "\n",
    "The [snapshot()](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.snapshot.html#chainer.training.extensions.snapshot) method saves the [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) object at the designated timing (defaut: every epoch) in the directory specified by `out`. The [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) object, as mentioned before, has an [Updater](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Updater.html#chainer.training.Updater) which contains an [Optimizer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Optimizer.html#chainer.Optimizer) and a model inside. Therefore, as long as you have the snapshot file, you can use it to come back to the training or make inferences using the previously trained model later.\n",
    "\n",
    "## [snapshot_object()](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.snapshot_object.html#chainer.training.extensions.snapshot_object)\n",
    "\n",
    "By using this, you can save the particular object (for example, the model object wrapped by [Classifier](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier)) as a separeted snapshot. [Classifier](https://docs.chainer.org/en/latest/reference/generated/chainer.links.Classifier.html#chainer.links.Classifier) is a [Chain](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Chain.html#chainer.Chain) object which keeps the model that is also a [Chain](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Chain.html#chainer.Chain) object as its `predictor` property, and all the parameters are under the `predictor`, so taking the snapshot of `predictor` is enough to keep all the trained parameters basically.\n",
    "\n",
    "## [dump_graph()](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.dump_graph.html#chainer.training.extensions.dump_graph)\n",
    "\n",
    "This method save the structure of the computational graph of the model. The graph is saved in the [Graphviz](http://www.graphviz.org/)'s `dot` format. The output location (directory) to save the graph is set by the `out` argument of [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer).\n",
    "\n",
    "## [Evaluator](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.Evaluator.html#chainer.training.extensions.Evaluator)\n",
    "\n",
    "The [Iterator](https://docs.chainer.org/en/latest/reference/core/generated/chainer.dataset.Iterator.html#chainer.dataset.Iterator) that uses the evaluation dataset and the model object are required to use [Evaluator](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.Evaluator.html#chainer.training.extensions.Evaluator). It evaluates the model using the given dataset (typically it’s a validation dataset) at the specified timing interval.\n",
    "\n",
    "## [PrintReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.PrintReport.html#chainer.training.extensions.PrintReport)\n",
    "\n",
    "It outputs the spcified values to the standard output.\n",
    "\n",
    "## [PlotReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.PlotReport.html#chainer.training.extensions.PlotReport)\n",
    "\n",
    "[PlotReport](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.PlotReport.html#chainer.training.extensions.PlotReport) plots the values specified by its arguments saves it as a image file which has the same naem as the `file_name` argument.\n",
    "\n",
    "---\n",
    "\n",
    "Each [Extension](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Extension.html#chainer.training.Extension) class has different options and some extensions are not mentioned here. And one of other important feature is, for instance, by using the [trigger](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Extension.html#chainer.training.Extension.trigger) option, you can set individual timings to fire the [Extension](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Extension.html#chainer.training.Extension). \n",
    "\n",
    "**To know more details of all extensions, please take a look at the official document: [Trainer extensions](https://docs.chainer.org/en/stable/reference/extensions.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 7. Start Training\n",
    "\n",
    "Just call `run()` method from [Trainer](https://docs.chainer.org/en/latest/reference/core/generated/chainer.training.Trainer.html#chainer.training.Trainer) object to start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let’s see the plot of loss progress saved in the mnist_result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('mnist_result/loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How about the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Image('mnist_result/accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Furthermore, let’s visualize the computaional graph saved with dump_graph() using Graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "dot -Tpng mnist_result/cg.dot -o mnist_result/cg.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Image('mnist_result/cg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From the top to the bottom, you can see the data flow in the computational graph. It basically shows how data and parameters are passed to the [Function](https://docs.chainer.org/en/latest/reference/core/generated/chainer.Function.html#chainer.Function)s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 8. Evaluate a pre-trained model\n",
    "\n",
    "Evaluation using the snapshot of a model is as easy as what explained in the tutorial/train_loop.rst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = MLP()\n",
    "serializers.load_npz('mnist_result/model_epoch-10', model)\n",
    "\n",
    "# Show the output\n",
    "x, t = test[0]\n",
    "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "print('label:', t)\n",
    "\n",
    "y = model(x[None, ...])\n",
    "\n",
    "print('predicted_label:', y.data.argmax(axis=1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**The prediction looks correct. Yatta!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
